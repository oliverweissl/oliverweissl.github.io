---
layout: project_showcase
permalink: /project_showcase/hynea/
title: "HyperNet-Adaptation for Diffusion-Based Test Case
Generation"
description: "HyNeA provides dataset-free
controllability through hypernetworks, allowing targeted manipulation of the generative process without
relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning."
keywords: "DL testing, Diffusion Models, Generative AI"
favicon: "/project_showcase/hynea/images/embedding_imagenet.ico"

# Authors and affiliations
authors:
  - name: "Oliver Weißl"
    url: "https://oliverweissl.github.io"
    affiliation: [1, 2]
  - name: "Vincenzo Riccio"
    url: "https://p1ndsvin.github.io/"
    affiliation: [3]
  - name: "Severin Kacianka"
    url: "https://kacianka.at/"
    affiliation: [2]
  - name: "Andrea Stocco"
    url: "https://tsigalko18.github.io/"
    affiliation: [1, 2]

affiliations:
  - "Technical University of Munich"
  - "fortiss GmbH"
  - "University of Udine"

# Publication links
links:
  - type: "paper"
    url: "https://doi.org/..."
    icon: "ai ai-acm"  # or ai-ieee, ai-doi, etc.
    label: "Paper"
  - type: "arxiv"
    url: "https://arxiv.org/abs/2601.15041"
    icon: "ai ai-arxiv"
    label: "arXiv"
  - type: "code"
    url: "https://github.com/oliverweissl/SMOO/tree/archive/hynea/"
    icon: "fab fa-github"
    label: "Code"

# BibTeX citation
bibtex: |
  @article{yourkey2025,
    title={Your Paper Title},
    author={Author 1 and Author 2 and Author 3},
    journal={Conference/Journal Name},
    year={2025}
  }

# SEO and social sharing (optional)
og_image: "/project_showcase/hynea/images/teaser.jpg"
---

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">{{ page.title }}</h1>

          <!-- Authors (automatically generated from frontmatter) -->
          <div class="is-size-5 publication-authors">
            {% for author in page.authors %}
            <span class="author-block">
              {% if author.url %}
              <a href="{{ author.url }}" target="_blank">{{ author.name }}</a>
              {% else %}
              {{ author.name }}
              {% endif %}
              <sup>{{ author.affiliation | join: ',' }}</sup>{% unless forloop.last %},{% endunless %}
            </span>
            {% endfor %}
          </div>

          <!-- Affiliations (automatically generated from frontmatter) -->
          <div class="is-size-5 publication-authors">
            {% for affiliation in page.affiliations %}
            <span class="author-block">
              <sup>{{ forloop.index }}</sup>{{ affiliation }}{% unless forloop.last %},{% endunless %}
            </span>
            {% endfor %}
          </div>

          <!-- Links (automatically generated from frontmatter) -->
          <div class="column has-text-centered">
            <div class="publication-links">
              {% for link in page.links %}
              <span class="link-block">
                <a href="{{ link.url }}" class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon"><i class="{{ link.icon }}"></i></span>
                  <span>{{ link.label }}</span>
                </a>
              </span>
              {% endfor %}
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="{{ '/project_showcase/hynea/images/teaser.jpg' | relative_url }}" alt="Teaser image showing hynea for differen tasks."/>
      <h2 class="subtitle has-text-centered">
        Inputs generated by <span class="dnerf">HyNeA</span>, that induce failures to different SUTs<br/><i>(Multi-Class Classification, Multi-Class Binary Classification, Object Detection)</i>
      </h2>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The increasing deployment of deep learning systems requires systematic evaluation of their reliability in
            real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely
            correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative
            test generation methods offer an alternative but are often limited to simple datasets or constrained input
            domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited
            controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing
            method that enables direct and efficient control over diffusion-based generation. <span class="dnerf">HyNeA</span> provides dataset-free
            controllability through hypernetworks, allowing targeted manipulation of the generative process without
            relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning.
            <span class="dnerf">HyNeA</span> employs a distinct training strategy that supports instance-level tuning to identify failure-inducing
            test cases without requiring datasets that explicitly contain examples of similar failures. This approach
            enables the targeted generation of realistic failure cases at substantially lower computational cost than
            search-based methods. Experimental results show that <span class="dnerf">HyNeA</span> improves controllability and test diversity
            compared to existing generative test generators and generalizes to domains where failure-labeled training
            data is unavailable.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Add your custom sections below -->
<!-- Example: Method overview, Results, Comparisons, etc. -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Testing vision models with realistic failures</h2>
          <p>
            Many vision testing methods create failures that look unrealistic to humans. Traditional adversarial attacks rely on tiny pixel changes, while newer generative methods aim for realism but often introduce visible artifacts or unintended changes. This limits their usefulness for understanding how and why models fail in practice.
            Qualitative comparisons show that <span class="dnerf">HyNeA</span> produces more realistic failure-inducing images than prior generative approaches such as GiftBench and <span class="dnerf">Mimicry</span>. GiftBench often distorts the overall structure of an image during its search process, making results harder to interpret. <span class="dnerf">Mimicry</span> can generate diverse outputs, but these frequently change multiple aspects of an image at once, leading to ambiguous failures. In contrast, <span class="dnerf">HyNeA</span> preserves the original image structure and semantics while making focused changes that reliably trigger model errors.
            Because the generated images remain visually coherent and easy to understand, the resulting failures are more informative for debugging and analysis. This makes <span class="dnerf">HyNeA</span> better suited for functional testing, where realistic and interpretable failures are more valuable than synthetic or heavily distorted examples.          
          </p>
          <div>
            <img src="{{ '/project_showcase/hynea/images/comp.jpg' | relative_url }}" alt="Figure 2" style="width:100%; height:auto;">
            <h3 class="subtitle has-text-centered fig-caption">Comparison of Generated Origin - Target Pairs for Different Methods<br/>(<span class="dnerf">HyNeA</span>, <span class="dnerf">GIFTBench</span>, <span class="dnerf">Mimicry</span>)</h3>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Instance-level control through hypernetwork adaptation</h2>
          <p>
            <span class="dnerf">HyNeA</span> enables targeted failure generation by directly optimizing the image generation process against the system under test. It builds on diffusion models for high image quality, but introduces a hypernetwork that controls generation at the instance level rather than relying on pre-trained conditioning data.
            For each test case, <span class="dnerf">HyNeA</span> generates an image using a frozen diffusion model and evaluates it with the system under test. The model’s output is used to compute an objective that captures both the desired failure behavior and visual fidelity. This objective is then used to update only the hypernetwork parameters for that specific instance. The diffusion model itself remains unchanged.
            This design allows <span class="dnerf">HyNeA</span> to apply precise, task-specific control while preserving realism. Because control is learned per instance, <span class="dnerf">HyNeA</span> does not require paired datasets or predefined control signals. The same mechanism can be used across different vision tasks, such as classification, attribute prediction, and object detection, by adjusting only the objective function.
          </p>

          <!-- Example: Adding images in a grid -->
          
         <div>
           <img src="{{ '/project_showcase/hynea/images/loop.png' | relative_url }}" alt="Figure 1" style="width:100%; height:auto;">
           <h3 class="subtitle has-text-centered fig-caption">Component Interaction in HyNeA</h3>
         </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Executive summary</h2>
          <p>
            <span class="dnerf">HyNeA</span> is a diffusion-based test generation framework that produces realistic images optimized to expose functional weaknesses in vision systems. Its key contribution is per-instance hypernetwork adaptation, which enables targeted control of model behavior without paired control data or retraining the diffusion model.
            Experiments show that <span class="dnerf">HyNeA</span> consistently induces intended failures across multiple vision tasks while preserving visual quality and semantic structure. Compared to generative and search-based baselines, <span class="dnerf">HyNeA</span> provides stronger and more precise control over failure outcomes and requires fewer interactions with the system under test. Human evaluations confirm that HyNeA’s outputs are more realistic and easier to interpret.
            Overall, <span class="dnerf">HyNeA</span> demonstrates how diffusion models can be used as an active testing tool, enabling realistic, controlled, and efficient functional testing of vision models in settings that better reflect real-world behavior.          
          </p>
        </div>
      </div>
    </div>
  </div>
</section>