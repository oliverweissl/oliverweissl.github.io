---
layout: post
title: HyperNet-Adaptation for Diffusion-Based Test Case Generation
authors: Oliver WeiÃŸl, Vincenzo Riccio, Severin Kacianka, Andrea Stocco
link: https://oliverweissl.github.io/project_showcase/hynea
categories:
- papers
- preprint
---
This paper introduces a novel Diffusion based testing approach for deep learning systems, combining SUT feedback with weight adaptations in HyperNets. Unlike prior methods, HyNeA does not rely on curated datasets, making it more flexible in usecases.
For more information click on the *To the paper* button on the bottom of the page.
### Abstract:

> The increasing deployment of deep learning systems requires systematic evaluation of their reliability in real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative test generation methods offer an alternative but are often limited to simple datasets or constrained input domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing method that enables direct and efficient control over diffusion-based generation. HyNeA provides dataset-free controllability through hypernetworks, allowing targeted manipulation of the generative process without relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning. HyNeA employs a distinct training strategy that supports instance-level tuning to identify failure-inducing test cases without requiring datasets that explicitly contain examples of similar failures. This approach enables the targeted generation of realistic failure cases at substantially lower computational cost than search-based methods. Experimental results show that HyNeA improves controllability and test diversity compared to existing generative test generators and generalizes to domains where failure-labeled training data is unavailable.